defaults:
    - base_effnet

training_iters: 10
algorithm:
    _target_: src.algorithms.GdAlgorithm
    dataset: "${get_cls: src.data.LeafDataset}"
    model: 
      _target_: src.algorithms.ModelHub
      model_name: tf_efficientnet_b5.ns_jft_in1k
      pretrained: true
    epochs_per_iteration: 1
    data_loader_kwargs: 
      batch_size: 32
      shuffle: true
    loss:
      _target_: src.utils.CELoss
      smoothing: 0.2
    optimizer_factory: "${get_cls: torch.optim.Adam}"
    optimizer_kwargs:
      lr: 1e-4
    scheduler_factory: "${get_cls: torch.optim.lr_scheduler.CosineAnnealingLR}"
    scheduler_kwargs:
      T_max: 12483 # (training_iters*epochs_per_iterations - warm_up) * len(data_loader)
      eta_min: 1e-6
    scheduler_step_unit: batch
    warm_up: 1387 # 1 * len(data_loader)
wandb:
    group: exp_0
name: exp_0